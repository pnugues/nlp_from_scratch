{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech and Sequence Annotation\n",
    "A reimplementation of the Senna program described in [_Natural language processing (almost) from scratch_](https://arxiv.org/abs/1103.0398) by Collobert et al. (2011) with PyTorch.\n",
    "## Part 3: Annotation with Conditional Random Fields\n",
    "This part contains a reimplementation of the conditional random fields (CRF) class with two ways to compute the $\\delta$: one proposed in the paper, Sect. 3.3.2, and another one adopted by the `torchcrf` module. The CRF class is purely stochastic and cannot process mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!wget https://data.deepai.org/conll2003.zip\\n!unzip -u conll2003.zip\\n!mkdir datasets/conll2003\\n!mv train.txt valid.txt test.txt datasets/conll2003\\n!rm conll2003.zip\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install conlleval\n",
    "\"\"\"\n",
    "!wget https://data.deepai.org/conll2003.zip\n",
    "!unzip -u conll2003.zip\n",
    "!mkdir datasets/conll2003\n",
    "!mv train.txt valid.txt test.txt datasets/conll2003\n",
    "!rm conll2003.zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import conlleval\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import ud_datasets\n",
    "from conll_dictorizer import CoNLLDictorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words to build the vocabulary and the embedding vectors:\n",
    "* 0: Random embeddings: The embedding table contains only the words in the corpus. \n",
    "* 1: Senna embeddings only: The embedding table contains only the words in the embeddings vocabulary (Senna). All the other words share an `UNK` symbol and vector\n",
    "* 2: Senna + word embeddings: We create an embedding table for the words in corpus and in Senna. We  initialize the embeddings with Senna vectors when available, otherwise random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_EMBEDDINGS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'CONLL2003'   # 'EWT' 'CONLL2003' 'CONLL2000'\n",
    "TAGSET = 'IOBES'  # 'BIO' 'IOBES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets/'\n",
    "MODEL_PATH = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding files. You will possibly need to adjust the path\n",
    "EMBEDDINGS_FILE = DATASET_PATH + 'senna/embeddings/embeddings.txt'\n",
    "WORD_FILE = DATASET_PATH + 'senna/hash/words.lst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "CAPS_EMBEDDING_DIM = 5\n",
    "N_HU_1 = 300\n",
    "MINI_CORPUS = False\n",
    "LOWERCASE = True\n",
    "D_WIN = 2  # Context to the right and left. Size of the window 2 * D_WIN + 1, d_win in Senna paper\n",
    "SENNA_DELTAS = True # We compute the deltas as in the paper, Sect. 3.3.2, or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x33ea7d3b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(word_file: str, embs_file: str) -> dict[str, torch.FloatTensor]:\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    words = []\n",
    "    with open(word_file) as f:\n",
    "        for line in f:\n",
    "            word = line.strip()\n",
    "            words += [word]\n",
    "    with open(embs_file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            values = line.strip().split()\n",
    "            word = words[i]\n",
    "            vector = torch.FloatTensor(\n",
    "                list(map(float, values)))\n",
    "            embeddings[word] = vector\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = read_embeddings(WORD_FILE, EMBEDDINGS_FILE)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Corpus\n",
    "Collobert et al. did not describe their validation experiments. In CoNLL 2000, there is no validation set. Although not a good practice, we use the test set to validate the training procedure. We also follow Attardi, https://github.com/attardi/deepnl, and we merge the CoNLL 2003 training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-10 09:36:03'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'EWT':\n",
    "    train_sentences, val_sentences, test_sentences, column_names = ud_datasets.load_ud_en_ewt()\n",
    "    MODEL_NAME = 'pos_model'\n",
    "elif CORPUS == 'CONLL2003':\n",
    "    train_file = DATASET_PATH + 'conll2003/train.txt'\n",
    "    val_file = DATASET_PATH + 'conll2003/valid.txt'\n",
    "    test_file = DATASET_PATH + 'conll2003/test.txt'\n",
    "    with open(train_file) as f:\n",
    "        train_sentences = f.read().strip()\n",
    "    with open(val_file) as f:\n",
    "        val_sentences = f.read().strip()\n",
    "    with open(test_file) as f:\n",
    "        test_sentences = f.read().strip()\n",
    "    MODEL_NAME = 'ner_model'\n",
    "    column_names = ['FORM', 'PPOS', 'PCHUNK', 'NER']\n",
    "elif CORPUS == 'CONLL2000':\n",
    "    train_file = DATASET_PATH + 'conll2000/train.txt'\n",
    "    test_file = DATASET_PATH + 'conll2000/test.txt'\n",
    "    with open(train_file) as f:\n",
    "        train_sentences = f.read().strip()\n",
    "    with open(test_file) as f:\n",
    "        test_sentences = f.read().strip()\n",
    "    column_names = ['FORM', 'PPOS', 'CHUNK']\n",
    "    MODEL_NAME = 'chunker_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/ner_model_2025-03-10 09:36:03.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_FILE = MODEL_PATH + MODEL_NAME + '_' + \\\n",
    "    datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '.pt'\n",
    "MODEL_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup\n",
    "\n",
    "We use the test set as validation set for CoNLL 2000 and 2003. We add the validation set to the training set in CoNLL 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'CONLL2003':\n",
    "    train_sentences += '\\n\\n' + val_sentences\n",
    "    val_sentences = test_sentences\n",
    "if CORPUS == 'CONLL2000':\n",
    "    val_sentences = test_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictorizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the corpus word in a dictionary, where the keys are the CoNLL-U columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'EWT':\n",
    "    conll_dict = CoNLLDictorizer(column_names)\n",
    "elif CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "    conll_dict = CoNLLDictorizer(column_names, col_sep=' +')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = conll_dict.transform(train_sentences)\n",
    "val_dict = conll_dict.transform(val_sentences)\n",
    "test_dict = conll_dict.transform(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'FORM': '-DOCSTART-', 'PPOS': '-X-', 'PCHUNK': '-X-', 'NER': 'O'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'FORM': '-DOCSTART-', 'PPOS': '-X-', 'PCHUNK': '-X-', 'NER': 'O'}],\n",
       " [{'FORM': 'EU', 'PPOS': 'NNP', 'PCHUNK': 'B-NP', 'NER': 'B-ORG'},\n",
       "  {'FORM': 'rejects', 'PPOS': 'VBZ', 'PCHUNK': 'B-VP', 'NER': 'O'},\n",
       "  {'FORM': 'German', 'PPOS': 'JJ', 'PCHUNK': 'B-NP', 'NER': 'B-MISC'},\n",
       "  {'FORM': 'call', 'PPOS': 'NN', 'PCHUNK': 'I-NP', 'NER': 'O'},\n",
       "  {'FORM': 'to', 'PPOS': 'TO', 'PCHUNK': 'B-VP', 'NER': 'O'},\n",
       "  {'FORM': 'boycott', 'PPOS': 'VB', 'PCHUNK': 'I-VP', 'NER': 'O'},\n",
       "  {'FORM': 'British', 'PPOS': 'JJ', 'PCHUNK': 'B-NP', 'NER': 'B-MISC'},\n",
       "  {'FORM': 'lamb', 'PPOS': 'NN', 'PCHUNK': 'I-NP', 'NER': 'O'},\n",
       "  {'FORM': '.', 'PPOS': '.', 'PCHUNK': 'O', 'NER': 'O'}],\n",
       " [{'FORM': 'Peter', 'PPOS': 'NNP', 'PCHUNK': 'B-NP', 'NER': 'B-PER'},\n",
       "  {'FORM': 'Blackburn', 'PPOS': 'NNP', 'PCHUNK': 'I-NP', 'NER': 'I-PER'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion of BIO to IOBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIO2IOBES(sent_dicts: list[dict], tag='CHUNK'):\n",
    "    for sent_dict in sent_dicts:\n",
    "        for idx in range(len(sent_dict) - 1):\n",
    "            # B O -> S O\n",
    "            if sent_dict[idx][tag][0] == 'B' and sent_dict[idx + 1][tag][0] == 'O':\n",
    "                sent_dict[idx][tag] = 'S' + sent_dict[idx][tag][1:]\n",
    "            # B-NP B-VP -> E-NP B-VP\n",
    "            elif sent_dict[idx][tag][0] == 'B' and sent_dict[idx + 1][tag][0] == 'B':\n",
    "                sent_dict[idx][tag] = 'S' + sent_dict[idx][tag][1:]\n",
    "            # I O -> E O\n",
    "            elif sent_dict[idx][tag][0] == 'I' and sent_dict[idx + 1][tag][0] == 'O':\n",
    "                sent_dict[idx][tag] = 'E' + sent_dict[idx][tag][1:]\n",
    "            # I B -> E B\n",
    "            elif sent_dict[idx][tag][0] == 'I' and sent_dict[idx + 1][tag][0] == 'B':\n",
    "                sent_dict[idx][tag] = 'E' + sent_dict[idx][tag][1:]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # Last word\n",
    "        if sent_dict[-1][tag][0] == 'B':\n",
    "            sent_dict[-1][tag] = 'S' + sent_dict[-1][tag][1:]\n",
    "        elif sent_dict[-1][tag][0] == 'I':\n",
    "            sent_dict[-1][tag] = 'E' + sent_dict[-1][tag][1:]\n",
    "        else:\n",
    "            pass\n",
    "    return sent_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TAGSET == 'IOBES' and CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "    if CORPUS == 'CONLL2000':\n",
    "        tag = 'CHUNK'\n",
    "    elif CORPUS == 'CONLL2003':\n",
    "        tag = 'NER'\n",
    "    train_dict = BIO2IOBES(train_dict, tag)\n",
    "    val_dict = BIO2IOBES(val_dict, tag)\n",
    "    test_dict = BIO2IOBES(test_dict, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'FORM': '-DOCSTART-', 'PPOS': '-X-', 'PCHUNK': '-X-', 'NER': 'O'}],\n",
       " [{'FORM': 'EU', 'PPOS': 'NNP', 'PCHUNK': 'B-NP', 'NER': 'S-ORG'},\n",
       "  {'FORM': 'rejects', 'PPOS': 'VBZ', 'PCHUNK': 'B-VP', 'NER': 'O'},\n",
       "  {'FORM': 'German', 'PPOS': 'JJ', 'PCHUNK': 'B-NP', 'NER': 'S-MISC'},\n",
       "  {'FORM': 'call', 'PPOS': 'NN', 'PCHUNK': 'I-NP', 'NER': 'O'},\n",
       "  {'FORM': 'to', 'PPOS': 'TO', 'PCHUNK': 'B-VP', 'NER': 'O'},\n",
       "  {'FORM': 'boycott', 'PPOS': 'VB', 'PCHUNK': 'I-VP', 'NER': 'O'},\n",
       "  {'FORM': 'British', 'PPOS': 'JJ', 'PCHUNK': 'B-NP', 'NER': 'S-MISC'},\n",
       "  {'FORM': 'lamb', 'PPOS': 'NN', 'PCHUNK': 'I-NP', 'NER': 'O'},\n",
       "  {'FORM': '.', 'PPOS': '.', 'PCHUNK': 'O', 'NER': 'O'}],\n",
       " [{'FORM': 'Peter', 'PPOS': 'NNP', 'PCHUNK': 'B-NP', 'NER': 'B-PER'},\n",
       "  {'FORM': 'Blackburn', 'PPOS': 'NNP', 'PCHUNK': 'I-NP', 'NER': 'E-PER'}],\n",
       " [{'FORM': 'BRUSSELS', 'PPOS': 'NNP', 'PCHUNK': 'B-NP', 'NER': 'S-LOC'},\n",
       "  {'FORM': '1996-08-22', 'PPOS': 'CD', 'PCHUNK': 'I-NP', 'NER': 'O'}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the case information. We follow the Senna source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_case_info(row: dict):\n",
    "    \"\"\"Same as in Senna code\"\"\"\n",
    "    if (any(char.isupper() for char in row['FORM']) and\n",
    "            not any(char.islower() for char in row['FORM'])):\n",
    "        row['CAPS'] = 'ALL_CAPS'\n",
    "    elif row['FORM'][0].isupper():\n",
    "        row['CAPS'] = 'INIT_CAP'\n",
    "    elif any(char.isupper() for char in row['FORM']):\n",
    "        row['CAPS'] = 'HAS_CAP'\n",
    "    else:\n",
    "        row['CAPS'] = 'NO_CAPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_dict in train_dict:\n",
    "    for row in sent_dict:\n",
    "        add_case_info(row)\n",
    "for sent_dict in val_dict:\n",
    "    for row in sent_dict:\n",
    "        add_case_info(row)\n",
    "for sent_dict in test_dict:\n",
    "    for row in sent_dict:\n",
    "        add_case_info(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence, train: [{'FORM': '-DOCSTART-', 'PPOS': '-X-', 'PCHUNK': '-X-', 'NER': 'O', 'CAPS': 'ALL_CAPS'}]\n"
     ]
    }
   ],
   "source": [
    "if MINI_CORPUS:\n",
    "    train_dict = train_dict[:len(train_dict) // 5]\n",
    "print('First sentence, train:', train_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting $X_{cat}$ and $\\mathbf{y}$ the Context and Dictorizing it\n",
    "We extract windows of five words surrounding the word and we build a table. We do the same with the case information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cols(sent_dict, x='FORM', y='UPOS'):\n",
    "    (input, target) = ([], [])\n",
    "    for word in sent_dict:\n",
    "        input += [word[x]]\n",
    "        target += [word.get(y, None)]\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'EWT':\n",
    "    x_input = 'FORM'\n",
    "    y_output = 'UPOS'\n",
    "elif CORPUS == 'CONLL2000':\n",
    "    x_input = 'FORM'\n",
    "    y_output = 'CHUNK'\n",
    "elif CORPUS == 'CONLL2003':\n",
    "    x_input = 'FORM'\n",
    "    y_output = 'NER'\n",
    "\n",
    "train_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "              for sent_dict in train_dict]\n",
    "val_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "            for sent_dict in val_dict]\n",
    "test_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "             for sent_dict in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_words, train_sent_pos = zip(*train_cols)\n",
    "val_sent_words, val_sent_pos = zip(*val_cols)\n",
    "test_sent_words, test_sent_pos = zip(*test_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the words in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOWERCASE:\n",
    "    train_sent_words = [list(map(str.lower, sent_words))\n",
    "                        for sent_words in train_sent_words]\n",
    "    val_sent_words = [list(map(str.lower, sent_words))\n",
    "                      for sent_words in val_sent_words]\n",
    "    test_sent_words = [list(map(str.lower, sent_words))\n",
    "                       for sent_words in test_sent_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'said',\n",
       " 'talbott',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'scheduled',\n",
       " 'to',\n",
       " 'return',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " ',',\n",
       " 'would',\n",
       " 'also',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'his',\n",
       " 'canadian',\n",
       " 'counterpart',\n",
       " ',',\n",
       " 'gordon',\n",
       " 'smith',\n",
       " ',',\n",
       " 'in',\n",
       " 'ottawa',\n",
       " 'for',\n",
       " 'talks',\n",
       " 'that',\n",
       " 'would',\n",
       " 'include',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'in',\n",
       " 'haiti',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent_words[8131]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'EWT':\n",
    "    x_input = 'CAPS'\n",
    "    y_output = 'UPOS'\n",
    "elif CORPUS == 'CONLL2000':\n",
    "    x_input = 'CAPS'\n",
    "    y_output = 'CHUNK'\n",
    "elif CORPUS == 'CONLL2003':\n",
    "    x_input = 'CAPS'\n",
    "    y_output = 'NER'\n",
    "\n",
    "train_caps_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "                   for sent_dict in train_dict]\n",
    "val_caps_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "                 for sent_dict in val_dict]\n",
    "test_caps_cols = [extract_cols(sent_dict, x=x_input, y=y_output)\n",
    "                  for sent_dict in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_caps, _ = zip(*train_caps_cols)\n",
    "val_sent_caps, _ = zip(*val_caps_cols)\n",
    "test_sent_caps, _ = zip(*test_caps_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'NO_CAPS',\n",
       " 'INIT_CAP',\n",
       " 'NO_CAPS']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent_caps[8131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3  # We do not use BOS and EOS\n",
    "# We will pad y with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the $X$ and $\\mathbf{y}$ Categorical Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_cat(sentence: list[str],\n",
    "                 w_size: int = D_WIN) -> list[dict[int: str]]:\n",
    "    start_pads = ['__BOS__'] * w_size\n",
    "    end_pads = ['__EOS__'] * w_size\n",
    "    sentence = start_pads + sentence + end_pads\n",
    "    # We extract the features\n",
    "    X = []\n",
    "    for i in range(len(sentence) - 2 * w_size):\n",
    "        x = []\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x += [sentence[i + j]]\n",
    "        X += [x]\n",
    "    X = [dict(enumerate(x)) for x in X]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: '__BOS__', 1: '__BOS__', 2: 'hong', 3: 'kong', 4: '1996-08-23'},\n",
       " {0: '__BOS__', 1: 'hong', 2: 'kong', 3: '1996-08-23', 4: '__EOS__'},\n",
       " {0: 'hong', 1: 'kong', 2: '1996-08-23', 3: '__EOS__', 4: '__EOS__'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_X_cat(train_sent_words[3000], w_size=D_WIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: '__BOS__', 1: '__BOS__', 2: 'ALL_CAPS', 3: 'ALL_CAPS', 4: 'NO_CAPS'},\n",
       " {0: '__BOS__', 1: 'ALL_CAPS', 2: 'ALL_CAPS', 3: 'NO_CAPS', 4: '__EOS__'},\n",
       " {0: 'ALL_CAPS', 1: 'ALL_CAPS', 2: 'NO_CAPS', 3: '__EOS__', 4: '__EOS__'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_X_cat(train_sent_caps[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = [create_X_cat(sent) for sent in train_sent_words]\n",
    "X_val_cat = [create_X_cat(sent) for sent in val_sent_words]\n",
    "X_test_cat = [create_X_cat(sent) for sent in test_sent_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: '__BOS__', 1: '__BOS__', 2: '-docstart-', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'eu', 3: 'rejects', 4: 'german'},\n",
       "  {0: '__BOS__', 1: 'eu', 2: 'rejects', 3: 'german', 4: 'call'},\n",
       "  {0: 'eu', 1: 'rejects', 2: 'german', 3: 'call', 4: 'to'},\n",
       "  {0: 'rejects', 1: 'german', 2: 'call', 3: 'to', 4: 'boycott'},\n",
       "  {0: 'german', 1: 'call', 2: 'to', 3: 'boycott', 4: 'british'},\n",
       "  {0: 'call', 1: 'to', 2: 'boycott', 3: 'british', 4: 'lamb'},\n",
       "  {0: 'to', 1: 'boycott', 2: 'british', 3: 'lamb', 4: '.'},\n",
       "  {0: 'boycott', 1: 'british', 2: 'lamb', 3: '.', 4: '__EOS__'},\n",
       "  {0: 'british', 1: 'lamb', 2: '.', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'peter', 3: 'blackburn', 4: '__EOS__'},\n",
       "  {0: '__BOS__', 1: 'peter', 2: 'blackburn', 3: '__EOS__', 4: '__EOS__'}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_caps_cat = [create_X_cat(sent) for sent in train_sent_caps]\n",
    "X_val_caps_cat = [create_X_cat(sent) for sent in val_sent_caps]\n",
    "X_test_caps_cat = [create_X_cat(sent) for sent in test_sent_caps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: '__BOS__', 1: '__BOS__', 2: 'ALL_CAPS', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'ALL_CAPS', 3: 'NO_CAPS', 4: 'INIT_CAP'},\n",
       "  {0: '__BOS__', 1: 'ALL_CAPS', 2: 'NO_CAPS', 3: 'INIT_CAP', 4: 'NO_CAPS'},\n",
       "  {0: 'ALL_CAPS', 1: 'NO_CAPS', 2: 'INIT_CAP', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'INIT_CAP', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'INIT_CAP', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: 'INIT_CAP'},\n",
       "  {0: 'NO_CAPS', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: 'INIT_CAP', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'NO_CAPS', 2: 'INIT_CAP', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'INIT_CAP', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: '__EOS__'},\n",
       "  {0: 'INIT_CAP', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'INIT_CAP', 3: 'INIT_CAP', 4: '__EOS__'},\n",
       "  {0: '__BOS__', 1: 'INIT_CAP', 2: 'INIT_CAP', 3: '__EOS__', 4: '__EOS__'}]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_caps_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = train_sent_pos\n",
    "y_val_cat = val_sent_pos\n",
    "y_test_cat = test_sent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O'],\n",
       " ['S-ORG', 'O', 'S-MISC', 'O', 'O', 'O', 'S-MISC', 'O', 'O'],\n",
       " ['B-PER', 'E-PER'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: '__BOS__', 1: '__BOS__', 2: '-docstart-', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'eu', 3: 'rejects', 4: 'german'},\n",
       "  {0: '__BOS__', 1: 'eu', 2: 'rejects', 3: 'german', 4: 'call'},\n",
       "  {0: 'eu', 1: 'rejects', 2: 'german', 3: 'call', 4: 'to'},\n",
       "  {0: 'rejects', 1: 'german', 2: 'call', 3: 'to', 4: 'boycott'},\n",
       "  {0: 'german', 1: 'call', 2: 'to', 3: 'boycott', 4: 'british'},\n",
       "  {0: 'call', 1: 'to', 2: 'boycott', 3: 'british', 4: 'lamb'},\n",
       "  {0: 'to', 1: 'boycott', 2: 'british', 3: 'lamb', 4: '.'},\n",
       "  {0: 'boycott', 1: 'british', 2: 'lamb', 3: '.', 4: '__EOS__'},\n",
       "  {0: 'british', 1: 'lamb', 2: '.', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'peter', 3: 'blackburn', 4: '__EOS__'},\n",
       "  {0: '__BOS__', 1: 'peter', 2: 'blackburn', 3: '__EOS__', 4: '__EOS__'}]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique words seen in training corpus: 23868\n"
     ]
    }
   ],
   "source": [
    "corpus_words = [value.lower() for l in X_train_cat for x in l\n",
    "                for value in x.values()]\n",
    "corpus_words = sorted(set(corpus_words))\n",
    "\n",
    "print('# unique words seen in training corpus:', len(corpus_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all the caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL_CAPS', 'HAS_CAP', 'INIT_CAP', 'NO_CAPS', '__BOS__', '__EOS__']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_caps = [value for l in X_train_caps_cat for x in l\n",
    "               for value in x.values()]\n",
    "corpus_caps = sorted(set(corpus_caps))\n",
    "corpus_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in Senna: 130000\n"
     ]
    }
   ],
   "source": [
    "embeddings_words = embeddings_dict.keys()\n",
    "print('Words in Senna:',  len(embeddings_dict.keys()))\n",
    "if USE_EMBEDDINGS == 0:\n",
    "    vocabulary = set(corpus_words)\n",
    "elif USE_EMBEDDINGS == 1:\n",
    "    # If we only use the words from Senna\n",
    "    vocabulary = set(list(embeddings_words))\n",
    "elif USE_EMBEDDINGS == 2:\n",
    "    vocabulary = set(corpus_words + list(embeddings_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique words in the vocabulary: embeddings and corpus: 136492\n"
     ]
    }
   ],
   "source": [
    "print('# unique words in the vocabulary: embeddings and corpus:',\n",
    "      len(vocabulary) + 2)  # unk and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = dict(enumerate(sorted(vocabulary), start=2))  # UNK: 0 and PAD: 1\n",
    "word2idx = {v: k for k, v in idx2word.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the words in lowercase as SENNA is in lowercase and we replace them with their index. The unknown word has the index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: '__BOS__', 1: '__BOS__', 2: '-docstart-', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'eu', 3: 'rejects', 4: 'german'},\n",
       "  {0: '__BOS__', 1: 'eu', 2: 'rejects', 3: 'german', 4: 'call'},\n",
       "  {0: 'eu', 1: 'rejects', 2: 'german', 3: 'call', 4: 'to'},\n",
       "  {0: 'rejects', 1: 'german', 2: 'call', 3: 'to', 4: 'boycott'},\n",
       "  {0: 'german', 1: 'call', 2: 'to', 3: 'boycott', 4: 'british'},\n",
       "  {0: 'call', 1: 'to', 2: 'boycott', 3: 'british', 4: 'lamb'},\n",
       "  {0: 'to', 1: 'boycott', 2: 'british', 3: 'lamb', 4: '.'},\n",
       "  {0: 'boycott', 1: 'british', 2: 'lamb', 3: '.', 4: '__EOS__'},\n",
       "  {0: 'british', 1: 'lamb', 2: '.', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'peter', 3: 'blackburn', 4: '__EOS__'},\n",
       "  {0: '__BOS__', 1: 'peter', 2: 'blackburn', 3: '__EOS__', 4: '__EOS__'}]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_train_cat in X_train_cat:\n",
    "    for x_train_cat in s_train_cat:\n",
    "        for word in x_train_cat:\n",
    "            x_train_cat[word] = word2idx.get(\n",
    "                x_train_cat[word].lower(), UNK_IDX)\n",
    "\n",
    "for s_val_cat in X_val_cat:\n",
    "    for x_val_cat in s_val_cat:\n",
    "        for word in x_val_cat:\n",
    "            x_val_cat[word] = word2idx.get(\n",
    "                x_val_cat[word].lower(), UNK_IDX)\n",
    "\n",
    "for s_test_cat in X_test_cat:\n",
    "    for x_test_cat in s_test_cat:\n",
    "        for word in x_test_cat:\n",
    "            x_test_cat[word] = word2idx.get(\n",
    "                x_test_cat[word].lower(), UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: 6168, 1: 6168, 2: 793, 3: 6169, 4: 6169}],\n",
       " [{0: 6168, 1: 6168, 2: 43539, 3: 102381, 4: 51127},\n",
       "  {0: 6168, 1: 43539, 2: 102381, 3: 51127, 4: 23294},\n",
       "  {0: 43539, 1: 102381, 2: 51127, 3: 23294, 4: 123348},\n",
       "  {0: 102381, 1: 51127, 2: 23294, 3: 123348, 4: 20585},\n",
       "  {0: 51127, 1: 23294, 2: 123348, 3: 20585, 4: 21362},\n",
       "  {0: 23294, 1: 123348, 2: 20585, 3: 21362, 4: 70048},\n",
       "  {0: 123348, 1: 20585, 2: 21362, 3: 70048, 4: 794},\n",
       "  {0: 20585, 1: 21362, 2: 70048, 3: 794, 4: 6169},\n",
       "  {0: 21362, 1: 70048, 2: 794, 3: 6169, 4: 6169}],\n",
       " [{0: 6168, 1: 6168, 2: 93450, 3: 18843, 4: 6169},\n",
       "  {0: 6168, 1: 93450, 2: 18843, 3: 6169, 4: 6169}],\n",
       " [{0: 6168, 1: 6168, 2: 21745, 3: 3285, 4: 6169},\n",
       "  {0: 6168, 1: 21745, 2: 3285, 3: 6169, 4: 6169}],\n",
       " [{0: 6168, 1: 6168, 2: 121983, 3: 43697, 4: 29447},\n",
       "  {0: 6168, 1: 121983, 2: 43697, 3: 29447, 4: 106629},\n",
       "  {0: 121983, 1: 43697, 2: 29447, 3: 106629, 4: 88585},\n",
       "  {0: 43697, 1: 29447, 2: 106629, 3: 88585, 4: 122699},\n",
       "  {0: 29447, 1: 106629, 2: 88585, 3: 122699, 4: 63622},\n",
       "  {0: 106629, 1: 88585, 2: 122699, 3: 63622, 4: 37226},\n",
       "  {0: 88585, 1: 122699, 2: 63622, 3: 37226, 4: 133627},\n",
       "  {0: 122699, 1: 63622, 2: 37226, 3: 133627, 4: 51127},\n",
       "  {0: 63622, 1: 37226, 2: 133627, 3: 51127, 4: 7706},\n",
       "  {0: 37226, 1: 133627, 2: 51127, 3: 7706, 4: 123348},\n",
       "  {0: 133627, 1: 51127, 2: 7706, 3: 123348, 4: 30616},\n",
       "  {0: 51127, 1: 7706, 2: 123348, 3: 30616, 4: 123348},\n",
       "  {0: 7706, 1: 123348, 2: 30616, 3: 123348, 4: 111710},\n",
       "  {0: 123348, 1: 30616, 2: 123348, 3: 111710, 4: 21362},\n",
       "  {0: 30616, 1: 123348, 2: 111710, 3: 21362, 4: 70048},\n",
       "  {0: 123348, 1: 111710, 2: 21362, 3: 70048, 4: 127997},\n",
       "  {0: 111710, 1: 21362, 2: 70048, 3: 127997, 4: 108489},\n",
       "  {0: 21362, 1: 70048, 2: 127997, 3: 108489, 4: 36239},\n",
       "  {0: 70048, 1: 127997, 2: 108489, 3: 36239, 4: 132803},\n",
       "  {0: 127997, 1: 108489, 2: 36239, 3: 132803, 4: 74834},\n",
       "  {0: 108489, 1: 36239, 2: 132803, 3: 74834, 4: 31864},\n",
       "  {0: 36239, 1: 132803, 2: 74834, 3: 31864, 4: 37411},\n",
       "  {0: 132803, 1: 74834, 2: 31864, 3: 37411, 4: 23574},\n",
       "  {0: 74834, 1: 31864, 2: 37411, 3: 23574, 4: 16652},\n",
       "  {0: 31864, 1: 37411, 2: 23574, 3: 16652, 4: 124553},\n",
       "  {0: 37411, 1: 23574, 2: 16652, 3: 124553, 4: 123348},\n",
       "  {0: 23574, 1: 16652, 2: 124553, 3: 123348, 4: 110900},\n",
       "  {0: 16652, 1: 124553, 2: 123348, 3: 110900, 4: 794},\n",
       "  {0: 124553, 1: 123348, 2: 110900, 3: 794, 4: 6169},\n",
       "  {0: 123348, 1: 110900, 2: 794, 3: 6169, 4: 6169}]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL_CAPS', 'HAS_CAP', 'INIT_CAP', 'NO_CAPS', '__BOS__', '__EOS__']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capset = sorted(set(corpus_caps))\n",
    "capset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'ALL_CAPS',\n",
       "  1: 'HAS_CAP',\n",
       "  2: 'INIT_CAP',\n",
       "  3: 'NO_CAPS',\n",
       "  4: '__BOS__',\n",
       "  5: '__EOS__'},\n",
       " {'ALL_CAPS': 0,\n",
       "  'HAS_CAP': 1,\n",
       "  'INIT_CAP': 2,\n",
       "  'NO_CAPS': 3,\n",
       "  '__BOS__': 4,\n",
       "  '__EOS__': 5})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2cap = dict(enumerate(capset))\n",
    "cap2idx = {v: k for k, v in idx2cap.items()}\n",
    "idx2cap, cap2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: '__BOS__', 1: '__BOS__', 2: 'ALL_CAPS', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'ALL_CAPS', 3: 'NO_CAPS', 4: 'INIT_CAP'},\n",
       "  {0: '__BOS__', 1: 'ALL_CAPS', 2: 'NO_CAPS', 3: 'INIT_CAP', 4: 'NO_CAPS'},\n",
       "  {0: 'ALL_CAPS', 1: 'NO_CAPS', 2: 'INIT_CAP', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'INIT_CAP', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'INIT_CAP', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: 'INIT_CAP'},\n",
       "  {0: 'NO_CAPS', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: 'INIT_CAP', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'NO_CAPS', 2: 'INIT_CAP', 3: 'NO_CAPS', 4: 'NO_CAPS'},\n",
       "  {0: 'NO_CAPS', 1: 'INIT_CAP', 2: 'NO_CAPS', 3: 'NO_CAPS', 4: '__EOS__'},\n",
       "  {0: 'INIT_CAP', 1: 'NO_CAPS', 2: 'NO_CAPS', 3: '__EOS__', 4: '__EOS__'}],\n",
       " [{0: '__BOS__', 1: '__BOS__', 2: 'INIT_CAP', 3: 'INIT_CAP', 4: '__EOS__'},\n",
       "  {0: '__BOS__', 1: 'INIT_CAP', 2: 'INIT_CAP', 3: '__EOS__', 4: '__EOS__'}]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_caps_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in X_train_caps_cat:\n",
    "    for row in sent:\n",
    "        for cap in row:\n",
    "            row[cap] = cap2idx.get(row[cap])\n",
    "\n",
    "for sent in X_val_caps_cat:\n",
    "    for row in sent:\n",
    "        for cap in row:\n",
    "            row[cap] = cap2idx.get(row[cap])\n",
    "\n",
    "for sent in X_test_caps_cat:\n",
    "    for row in sent:\n",
    "        for cap in row:\n",
    "            row[cap] = cap2idx.get(row[cap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{0: 4, 1: 4, 2: 0, 3: 5, 4: 5}],\n",
       " [{0: 4, 1: 4, 2: 0, 3: 3, 4: 2},\n",
       "  {0: 4, 1: 0, 2: 3, 3: 2, 4: 3},\n",
       "  {0: 0, 1: 3, 2: 2, 3: 3, 4: 3},\n",
       "  {0: 3, 1: 2, 2: 3, 3: 3, 4: 3},\n",
       "  {0: 2, 1: 3, 2: 3, 3: 3, 4: 2},\n",
       "  {0: 3, 1: 3, 2: 3, 3: 2, 4: 3},\n",
       "  {0: 3, 1: 3, 2: 2, 3: 3, 4: 3},\n",
       "  {0: 3, 1: 2, 2: 3, 3: 3, 4: 5},\n",
       "  {0: 2, 1: 3, 2: 3, 3: 5, 4: 5}],\n",
       " [{0: 4, 1: 4, 2: 2, 3: 2, 4: 5}, {0: 4, 1: 2, 2: 2, 3: 5, 4: 5}]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_caps_cat[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the ${X}$ Matrix.\n",
    "We create two embedding matrices, for the words and the case information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.int64&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DictVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.DictVectorizer.html\">?<span>Documentation for DictVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.int64&#x27;&gt;, sparse=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.int64'>, sparse=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vect_words = DictVectorizer(dtype=np.int64, sparse=False)\n",
    "dict_vect_words.fit([row for sent in X_train_cat for row in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [dict_vect_words.transform(sent) for sent in X_train_cat]\n",
    "X_val = [dict_vect_words.transform(sent) for sent in X_val_cat]\n",
    "X_test = [dict_vect_words.transform(sent) for sent in X_test_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6168, 6168,  793, 6169, 6169]]),\n",
       " array([[  6168,   6168,  43539, 102381,  51127],\n",
       "        [  6168,  43539, 102381,  51127,  23294],\n",
       "        [ 43539, 102381,  51127,  23294, 123348],\n",
       "        [102381,  51127,  23294, 123348,  20585],\n",
       "        [ 51127,  23294, 123348,  20585,  21362],\n",
       "        [ 23294, 123348,  20585,  21362,  70048],\n",
       "        [123348,  20585,  21362,  70048,    794],\n",
       "        [ 20585,  21362,  70048,    794,   6169],\n",
       "        [ 21362,  70048,    794,   6169,   6169]]),\n",
       " array([[ 6168,  6168, 93450, 18843,  6169],\n",
       "        [ 6168, 93450, 18843,  6169,  6169]]),\n",
       " array([[ 6168,  6168, 21745,  3285,  6169],\n",
       "        [ 6168, 21745,  3285,  6169,  6169]]),\n",
       " array([[  6168,   6168, 121983,  43697,  29447],\n",
       "        [  6168, 121983,  43697,  29447, 106629],\n",
       "        [121983,  43697,  29447, 106629,  88585],\n",
       "        [ 43697,  29447, 106629,  88585, 122699],\n",
       "        [ 29447, 106629,  88585, 122699,  63622],\n",
       "        [106629,  88585, 122699,  63622,  37226],\n",
       "        [ 88585, 122699,  63622,  37226, 133627],\n",
       "        [122699,  63622,  37226, 133627,  51127],\n",
       "        [ 63622,  37226, 133627,  51127,   7706],\n",
       "        [ 37226, 133627,  51127,   7706, 123348],\n",
       "        [133627,  51127,   7706, 123348,  30616],\n",
       "        [ 51127,   7706, 123348,  30616, 123348],\n",
       "        [  7706, 123348,  30616, 123348, 111710],\n",
       "        [123348,  30616, 123348, 111710,  21362],\n",
       "        [ 30616, 123348, 111710,  21362,  70048],\n",
       "        [123348, 111710,  21362,  70048, 127997],\n",
       "        [111710,  21362,  70048, 127997, 108489],\n",
       "        [ 21362,  70048, 127997, 108489,  36239],\n",
       "        [ 70048, 127997, 108489,  36239, 132803],\n",
       "        [127997, 108489,  36239, 132803,  74834],\n",
       "        [108489,  36239, 132803,  74834,  31864],\n",
       "        [ 36239, 132803,  74834,  31864,  37411],\n",
       "        [132803,  74834,  31864,  37411,  23574],\n",
       "        [ 74834,  31864,  37411,  23574,  16652],\n",
       "        [ 31864,  37411,  23574,  16652, 124553],\n",
       "        [ 37411,  23574,  16652, 124553, 123348],\n",
       "        [ 23574,  16652, 124553, 123348, 110900],\n",
       "        [ 16652, 124553, 123348, 110900,    794],\n",
       "        [124553, 123348, 110900,    794,   6169],\n",
       "        [123348, 110900,    794,   6169,   6169]])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [torch.from_numpy(X) for X in X_train]\n",
    "X_val = [torch.from_numpy(X) for X in X_val]\n",
    "X_test = [torch.from_numpy(X) for X in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  6168,   6168,  96033,  30030,  49116],\n",
       "         [  6168,  96033,  30030,  49116,  72944],\n",
       "         [ 96033,  30030,  49116,  72944, 111257],\n",
       "         [ 30030,  49116,  72944, 111257,  62295],\n",
       "         [ 49116,  72944, 111257,  62295, 110134],\n",
       "         [ 72944, 111257,  62295, 110134,    725],\n",
       "         [111257,  62295, 110134,    725,   6169],\n",
       "         [ 62295, 110134,    725,   6169,   6169]]),\n",
       " tensor([[  6168,   6168,  70660,    722,  13905],\n",
       "         [  6168,  70660,    722,  13905,   2286],\n",
       "         [ 70660,    722,  13905,   2286,    723],\n",
       "         [   722,  13905,   2286,    723, 131278],\n",
       "         [ 13905,   2286,    723, 131278, 122998],\n",
       "         [  2286,    723, 131278, 122998,  13505],\n",
       "         [   723, 131278, 122998,  13505,  70660],\n",
       "         [131278, 122998,  13505,  70660,  10614],\n",
       "         [122998,  13505,  70660,  10614, 120579],\n",
       "         [ 13505,  70660,  10614, 120579,  97131],\n",
       "         [ 70660,  10614, 120579,  97131,   3807],\n",
       "         [ 10614, 120579,  97131,   3807,  58801],\n",
       "         [120579,  97131,   3807,  58801,    794],\n",
       "         [ 97131,   3807,  58801,    794,   6169],\n",
       "         [  3807,  58801,    794,   6169,   6169]]),\n",
       " tensor([[6168, 6168,  793, 6169, 6169]]),\n",
       " tensor([[  6168,   6168,  63553,  95042,  38741],\n",
       "         [  6168,  63553,  95042,  38741,  45698],\n",
       "         [ 63553,  95042,  38741,  45698,  87976],\n",
       "         [ 95042,  38741,  45698,  87976, 131549],\n",
       "         [ 38741,  45698,  87976, 131549, 133627],\n",
       "         [ 45698,  87976, 131549, 133627, 119558],\n",
       "         [ 87976, 131549, 133627, 119558,    794],\n",
       "         [131549, 133627, 119558,    794,   6169],\n",
       "         [133627, 119558,    794,   6169,   6169]]),\n",
       " tensor([[  6168,   6168,  29008, 111934,   6169],\n",
       "         [  6168,  29008, 111934,   6169,   6169]])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.int64&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DictVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.DictVectorizer.html\">?<span>Documentation for DictVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.int64&#x27;&gt;, sparse=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.int64'>, sparse=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vect_caps = DictVectorizer(dtype=np.int64, sparse=False)\n",
    "dict_vect_caps.fit([row for sent in X_train_caps_cat for row in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_caps_train = [dict_vect_caps.transform(sent) for sent in X_train_caps_cat]\n",
    "X_caps_val = [dict_vect_caps.transform(sent) for sent in X_val_caps_cat]\n",
    "X_caps_test = [dict_vect_caps.transform(sent) for sent in X_test_caps_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_caps_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4, 4, 0, 5, 5]]),\n",
       " array([[4, 4, 0, 3, 2],\n",
       "        [4, 0, 3, 2, 3],\n",
       "        [0, 3, 2, 3, 3],\n",
       "        [3, 2, 3, 3, 3],\n",
       "        [2, 3, 3, 3, 2],\n",
       "        [3, 3, 3, 2, 3],\n",
       "        [3, 3, 2, 3, 3],\n",
       "        [3, 2, 3, 3, 5],\n",
       "        [2, 3, 3, 5, 5]]),\n",
       " array([[4, 4, 2, 2, 5],\n",
       "        [4, 2, 2, 5, 5]]),\n",
       " array([[4, 4, 0, 3, 5],\n",
       "        [4, 0, 3, 5, 5]]),\n",
       " array([[4, 4, 2, 2, 2],\n",
       "        [4, 2, 2, 2, 3],\n",
       "        [2, 2, 2, 3, 3],\n",
       "        [2, 2, 3, 3, 2],\n",
       "        [2, 3, 3, 2, 3],\n",
       "        [3, 3, 2, 3, 3],\n",
       "        [3, 2, 3, 3, 3],\n",
       "        [2, 3, 3, 3, 2],\n",
       "        [3, 3, 3, 2, 3],\n",
       "        [3, 3, 2, 3, 3],\n",
       "        [3, 2, 3, 3, 3],\n",
       "        [2, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 2],\n",
       "        [3, 3, 3, 2, 3],\n",
       "        [3, 3, 2, 3, 3],\n",
       "        [3, 2, 3, 3, 3],\n",
       "        [2, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 5],\n",
       "        [3, 3, 3, 5, 5]])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_caps_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_caps_train = [torch.from_numpy(X) for X in X_caps_train]\n",
    "X_caps_val = [torch.from_numpy(X) for X in X_caps_val]\n",
    "X_caps_test = [torch.from_numpy(X) for X in X_caps_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[4, 4, 0, 5, 5]]),\n",
       " tensor([[4, 4, 0, 3, 2],\n",
       "         [4, 0, 3, 2, 3],\n",
       "         [0, 3, 2, 3, 3],\n",
       "         [3, 2, 3, 3, 3],\n",
       "         [2, 3, 3, 3, 2],\n",
       "         [3, 3, 3, 2, 3],\n",
       "         [3, 3, 2, 3, 3],\n",
       "         [3, 2, 3, 3, 5],\n",
       "         [2, 3, 3, 5, 5]]),\n",
       " tensor([[4, 4, 2, 2, 5],\n",
       "         [4, 2, 2, 5, 5]])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_caps_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vectorizing $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a torch matrix of size $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in Senna, and $N$, the dimension of the embeddings.\n",
    "The unknown word symbol will be part of the vocabulary at index 0. \n",
    "\n",
    "We initialize the matrix with random values with the `torch.rand()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two rows for the unknown words at index 0 and padding at index 1\n",
    "embedding_table = (torch.rand(\n",
    "    (len(vocabulary) + 2, EMBEDDING_DIM)) - 0.5)/10  # range: -0.1, 0.1,\n",
    "# embedding_table = torch.rand((len(vocabulary) + 2, EMBEDDING_DIM)) - 0.5\n",
    "# embedding_table = torch.zeros((len(vocabulary) + 2, EMBEDDING_DIM))\n",
    "# embedding_table = torch.randn(\n",
    "#    (len(vocabulary) + 1, EMBEDDING_DIM))#/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([136492, 50])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the matrix with the Senna embeddings when available. This means: We replace the random vector with an embedding when available. We will use the indices from the previous section. We call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_embeddings = []\n",
    "for word in vocabulary:\n",
    "    if word in embeddings_dict:\n",
    "        # If the words are in the embeddings, we fill them with a value\n",
    "        embedding_table[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        # Otherwise, it keeps a random value in the matrix\n",
    "        # We store the out of vocabulary words\n",
    "        out_of_embeddings += [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6490"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['483',\n",
       " '11,046,000',\n",
       " '630.000',\n",
       " 'puertollano',\n",
       " '4-28',\n",
       " 'kafkas',\n",
       " 'outmaneuvering',\n",
       " '3,300',\n",
       " 'ruci',\n",
       " '5-365']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the unknown symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0471, -0.0098, -0.0240, -0.0133, -0.0442,  0.0201, -0.0448, -0.0032,\n",
       "         0.0174, -0.0169])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the Senna values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9408,  2.3745,  0.6668,  0.3591,  0.4177,  0.9110,  0.6482, -0.5022,\n",
       "         0.8337,  0.5341])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _extrcurricular_, a word in CoNLL, but not in Senna, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0456, -0.0119, -0.0084, -0.0348, -0.0076, -0.0241,  0.0141, -0.0244,\n",
      "        -0.0466,  0.0314])\n"
     ]
    }
   ],
   "source": [
    "if USE_EMBEDDINGS == 2:\n",
    "    if CORPUS == 'EWT':\n",
    "        print(embedding_table[word2idx['extrcurricular']][:10])\n",
    "    elif CORPUS == 'CONLL2003':\n",
    "        print(embedding_table[word2idx['idalecio']][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The POS and the number of different POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'E-LOC',\n",
       " 'E-MISC',\n",
       " 'E-ORG',\n",
       " 'E-PER',\n",
       " 'I-LOC',\n",
       " 'I-MISC',\n",
       " 'I-ORG',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'S-LOC',\n",
       " 'S-MISC',\n",
       " 'S-ORG',\n",
       " 'S-PER']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagset = sorted(set([y for sent in y_train_cat for y in sent]))\n",
    "pos_tagset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a part-of-speech index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'B-LOC', 2: 'B-MISC', 3: 'B-ORG', 4: 'B-PER', 5: 'E-LOC', 6: 'E-MISC', 7: 'E-ORG', 8: 'E-PER', 9: 'I-LOC', 10: 'I-MISC', 11: 'I-ORG', 12: 'I-PER', 13: 'O', 14: 'S-LOC', 15: 'S-MISC', 16: 'S-ORG', 17: 'S-PER', 0: 'PAD'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B-LOC': 1,\n",
       " 'B-MISC': 2,\n",
       " 'B-ORG': 3,\n",
       " 'B-PER': 4,\n",
       " 'E-LOC': 5,\n",
       " 'E-MISC': 6,\n",
       " 'E-ORG': 7,\n",
       " 'E-PER': 8,\n",
       " 'I-LOC': 9,\n",
       " 'I-MISC': 10,\n",
       " 'I-ORG': 11,\n",
       " 'I-PER': 12,\n",
       " 'O': 13,\n",
       " 'S-LOC': 14,\n",
       " 'S-MISC': 15,\n",
       " 'S-ORG': 16,\n",
       " 'S-PER': 17,\n",
       " 'PAD': 0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2pos = dict(enumerate(pos_tagset, start=1))  # pad: 0\n",
    "idx2pos[0] = 'PAD'\n",
    "pos2idx = {v: k for k, v in idx2pos.items()}\n",
    "print(idx2pos)\n",
    "pos2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O'],\n",
       " ['S-ORG', 'O', 'S-MISC', 'O', 'O', 'O', 'S-MISC', 'O', 'O'],\n",
       " ['B-PER', 'E-PER'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for sent in y_train_cat:\n",
    "    y_train += [torch.LongTensor([pos2idx[i] for i in sent])]\n",
    "y_val = []\n",
    "for sent in y_val_cat:\n",
    "    y_val += [torch.LongTensor([pos2idx.get(i, 0) for i in sent])]\n",
    "y_test = []\n",
    "for sent in y_test_cat:\n",
    "    y_test += [torch.LongTensor([pos2idx.get(i, 0) for i in sent])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([13]), tensor([16, 13, 15, 13, 13, 13, 15, 13, 13]), tensor([4, 8])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O'],\n",
       " ['S-ORG', 'O', 'S-MISC', 'O', 'O', 'O', 'S-MISC', 'O', 'O'],\n",
       " ['B-PER', 'E-PER'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([13, 13, 13,  3, 11, 11,  7, 13]),\n",
       " tensor([14, 13, 13, 13, 13, 13, 13, 13, 14, 13, 14, 13, 13, 13, 13]),\n",
       " tensor([13]),\n",
       " tensor([14, 13, 13, 13, 13, 13, 13, 14, 13]),\n",
       " tensor([4, 8])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136492, 18, 6)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocabulary) + 2  # unk and pad\n",
    "tagset_size = len(pos_tagset) + 1  # pad\n",
    "capset_size = len(capset)\n",
    "vocab_size, tagset_size, capset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagger():\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 word2idx,\n",
    "                 cap2idx,\n",
    "                 idx2pos,\n",
    "                 dict_vect_words,\n",
    "                 dict_vect_caps,\n",
    "                 ppos_key='PTAG',\n",
    "                 lc=True):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.word2idx = word2idx\n",
    "        self.cap2idx = cap2idx\n",
    "        self.idx2pos = idx2pos\n",
    "        self.dict_vect_words = dict_vect_words\n",
    "        self.dict_vect_caps = dict_vect_caps\n",
    "        self.ppos_key = ppos_key\n",
    "        self.lc = lc\n",
    "\n",
    "    def sent2dict(self, sentence: str):\n",
    "        sent_dict = [{'ID': x, 'FORM': y} for (x, y) in\n",
    "                     enumerate(sentence.split(), start=1)]\n",
    "        for row in sent_dict:\n",
    "            self.add_case_info(row)\n",
    "        return sent_dict\n",
    "\n",
    "    def add_case_info(self, row: dict):\n",
    "        if (any(char.isupper() for char in row['FORM']) and\n",
    "                not any(char.islower() for char in row['FORM'])):\n",
    "            row['CAPS'] = 'ALL_CAPS'\n",
    "        elif row['FORM'][0].isupper():\n",
    "            row['CAPS'] = 'INIT_CAP'\n",
    "        elif any(char.isupper() for char in row['FORM']):\n",
    "            row['CAPS'] = 'HAS_CAP'\n",
    "        else:\n",
    "            row['CAPS'] = 'NO_CAPS'\n",
    "\n",
    "    def predict(self, sentence: list[dict]) -> list[dict]:\n",
    "        self.model.eval()\n",
    "        sent_words, _ = extract_cols(sentence)\n",
    "        if self.lc:\n",
    "            sent_words = list(map(str.lower, sent_words))\n",
    "        X_cat = create_X_cat(sent_words)\n",
    "        for x_cat in X_cat:\n",
    "            for word in x_cat:\n",
    "                x_cat[word] = self.word2idx.get(x_cat[word].lower(), UNK_IDX)\n",
    "        X = self.dict_vect_words.transform(X_cat)\n",
    "\n",
    "        sent_caps, _ = extract_cols(sentence, x='CAPS')\n",
    "        X_caps_cat = create_X_cat(sent_caps)\n",
    "        for x_cat in X_caps_cat:\n",
    "            for word in x_cat:\n",
    "                x_cat[word] = self.cap2idx.get(x_cat[word])\n",
    "        X_caps = self.dict_vect_caps.transform(X_caps_cat)\n",
    "\n",
    "        X = torch.from_numpy(X)\n",
    "        X_caps = torch.from_numpy(X_caps)\n",
    "        X = torch.cat((X, X_caps), dim=-1)\n",
    "        y_pred_vec = self.model(X.long().unsqueeze(dim=0))\n",
    "        # We add the predictions in the PTAG column\n",
    "        # We need to remove the batch dimension\n",
    "        for row, y_pred in zip(sentence, y_pred_vec[0]):\n",
    "            row[self.ppos_key] = idx2pos[y_pred]\n",
    "        return sentence\n",
    "\n",
    "    def predict_sentences(self, sent_dicts: list[list[dict]]) -> list[list[dict]]:\n",
    "        pred_sents = []\n",
    "        for sentence in sent_dicts:\n",
    "            pred_sents += [self.predict(sentence)]\n",
    "        return pred_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoNLLScorer():\n",
    "    def __init__(self, column_names: list,\n",
    "                 true_tag='UPOS',\n",
    "                 pred_tag='PTAG'):\n",
    "        super().__init__()\n",
    "        self.true_tag = true_tag\n",
    "        self.pred_tag = pred_tag\n",
    "        self.column_names = column_names + [pred_tag]\n",
    "\n",
    "    def format_corpus(self, corpus_dict: list[list[dict]]) -> str:\n",
    "        self.tagged_corpus = ''\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: str(row.get(x, '_')), self.column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            self.tagged_corpus += ''.join(sentence_lst)\n",
    "        return self.tagged_corpus\n",
    "\n",
    "    def conll_score(self, corpus_dict: list[list[dict]]) -> float:\n",
    "        lines = self.format_corpus(corpus_dict).splitlines()\n",
    "        res = conlleval.evaluate(lines)\n",
    "        chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "        return chunker_score\n",
    "\n",
    "    def accuracy(self, corpus_dict: list[list[dict]]) -> float:\n",
    "        cnt = cnt_correct = 0\n",
    "        for dict in corpus_dict:\n",
    "            for row in dict:\n",
    "                cnt += 1\n",
    "                if row[self.true_tag] == row[self.pred_tag]:\n",
    "                    cnt_correct += 1\n",
    "        return cnt_correct/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    def __init__(self, tagset_size):\n",
    "        super(CRF, self).__init__()\n",
    "        self.tagset_size = tagset_size\n",
    "        self.start_transitions = nn.Parameter(torch.empty(tagset_size))\n",
    "        self.end_transitions = nn.Parameter(torch.empty(tagset_size))\n",
    "        self.transitions = nn.Parameter(torch.empty(tagset_size, tagset_size))\n",
    "\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "\n",
    "    def _compute_deltas_standard(self, logits):\n",
    "        delta = (self.start_transitions + logits[0]).unsqueeze(dim=0)\n",
    "        for logit in logits[1:]:\n",
    "            delta = torch.logsumexp(\n",
    "                delta.T + self.transitions + logit,\n",
    "                dim=0).unsqueeze(dim=0)\n",
    "        delta = delta + self.end_transitions\n",
    "        return torch.logsumexp(delta, dim=1).squeeze()\n",
    "\n",
    "    def _compute_deltas_senna(self, logits):\n",
    "        delta = (self.start_transitions + logits[0]).unsqueeze(dim=0)\n",
    "        for logit in logits[1:]:\n",
    "            logadd = torch.logsumexp(\n",
    "                delta.T + self.transitions,\n",
    "                dim=0).unsqueeze(dim=0)\n",
    "            delta = logadd + logit\n",
    "        delta += self.end_transitions\n",
    "        return torch.logsumexp(delta, dim=1).squeeze()\n",
    "\n",
    "    def _compute_sentence_score(self, logits, tags):\n",
    "        correct_path_score = self.start_transitions[tags[0]\n",
    "                                                    ] + logits[0][tags[0]]\n",
    "        for i, logit in enumerate(logits[1:]):\n",
    "            correct_path_score += self.transitions[tags[i],\n",
    "                                                   tags[i + 1]] + logit[tags[i + 1]]\n",
    "        correct_path_score += self.end_transitions[tags[-1]]\n",
    "        return correct_path_score\n",
    "\n",
    "    def _viterbi_decode(self, logits):\n",
    "        backpointers = []\n",
    "        max_llhoods = self.start_transitions + logits[0]\n",
    "\n",
    "        for logit in logits[1:]:\n",
    "            backpointers_t = []\n",
    "            max_llhoods_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                llhoods = max_llhoods + self.transitions[:, next_tag]\n",
    "                best_tag_id = torch.argmax(llhoods).item()\n",
    "                backpointers_t += [best_tag_id]\n",
    "                max_llhoods_t += [llhoods[best_tag_id]]\n",
    "            max_llhoods = (torch.tensor(max_llhoods_t) + logit)\n",
    "            backpointers += [backpointers_t]\n",
    "\n",
    "        max_llhoods += self.end_transitions\n",
    "        best_tag_id = torch.argmax(max_llhoods).item()\n",
    "        path_score = max_llhoods[best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for backpointers_t in backpointers[::-1]:\n",
    "            best_tag_id = backpointers_t[best_tag_id]\n",
    "            best_path += [best_tag_id]\n",
    "        return path_score, best_path[::-1]\n",
    "\n",
    "    def forward(self, logits, targets=None):\n",
    "        if targets is not None:\n",
    "            sent_score = self._compute_sentence_score(logits, targets)\n",
    "            if SENNA_DELTAS:\n",
    "                normalizing_score = self._compute_deltas_senna(logits)\n",
    "            else:\n",
    "                normalizing_score = self._compute_deltas_standard(logits)\n",
    "            return sent_score - normalizing_score\n",
    "        else:\n",
    "            return self._viterbi_decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d_win = 2 * D_WIN + 1  # Note that typically D_WIN = 2 and d_win = 5\n",
    "        self.word_embs = nn.Embedding.from_pretrained(\n",
    "            embedding_table, freeze=False)\n",
    "        #  self.word_embs = nn.Embedding(vocab_size, EMBEDDING_DIM)\n",
    "        self.cap_embs = nn.Embedding(\n",
    "            capset_size, CAPS_EMBEDDING_DIM)\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.d_win * (EMBEDDING_DIM + CAPS_EMBEDDING_DIM), N_HU_1)\n",
    "        self.hardth = nn.Hardtanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(N_HU_1,\n",
    "                             tagset_size)\n",
    "        self.crf = CRF(tagset_size)\n",
    "\n",
    "    def _get_nn_logits(self, x):\n",
    "        word_vects = self.word_embs(x[:, :, :self.d_win])\n",
    "        cap_vects = self.cap_embs(x[:, :, self.d_win:])\n",
    "        x = torch.cat((word_vects, cap_vects), dim=-1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        #  x = self.hardth(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, sentence, tags=None, mask=None):\n",
    "        nn_logits = self._get_nn_logits(sentence)\n",
    "        if tags is not None:\n",
    "            # Ajustement : retourne la perte\n",
    "            return -self.crf(nn_logits.squeeze(dim=0), tags.squeeze(dim=0))\n",
    "        else:\n",
    "            # Inférence : retourne la meilleure séquence\n",
    "            return [self.crf(nn_logits.squeeze(dim=0))[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Tagger(model,\n",
    "                word2idx,\n",
    "                cap2idx,\n",
    "                idx2pos,\n",
    "                dict_vect_words,\n",
    "                dict_vect_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging with a random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 1, 'FORM': 'That', 'CAPS': 'INIT_CAP'},\n",
       " {'ID': 2, 'FORM': 'round', 'CAPS': 'NO_CAPS'},\n",
       " {'ID': 3, 'FORM': 'table', 'CAPS': 'NO_CAPS'},\n",
       " {'ID': 4, 'FORM': 'in', 'CAPS': 'NO_CAPS'},\n",
       " {'ID': 5, 'FORM': 'Wall', 'CAPS': 'INIT_CAP'},\n",
       " {'ID': 6, 'FORM': 'Street', 'CAPS': 'INIT_CAP'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = tagger.sent2dict(\"That round table in Wall Street\")\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 1, 'FORM': 'That', 'CAPS': 'INIT_CAP', 'PTAG': 'PAD'},\n",
       " {'ID': 2, 'FORM': 'round', 'CAPS': 'NO_CAPS', 'PTAG': 'B-ORG'},\n",
       " {'ID': 3, 'FORM': 'table', 'CAPS': 'NO_CAPS', 'PTAG': 'I-ORG'},\n",
       " {'ID': 4, 'FORM': 'in', 'CAPS': 'NO_CAPS', 'PTAG': 'I-MISC'},\n",
       " {'ID': 5, 'FORM': 'Wall', 'CAPS': 'INIT_CAP', 'PTAG': 'I-MISC'},\n",
       " {'ID': 6, 'FORM': 'Street', 'CAPS': 'INIT_CAP', 'PTAG': 'E-ORG'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FORM', 'PPOS', 'PCHUNK', 'NER']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "    scorer = CoNLLScorer(column_names, true_tag='NER')\n",
    "elif CORPUS == 'EWT':\n",
    "    scorer = CoNLLScorer(column_names, true_tag='UPOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 1, 'FORM': 'That', 'CAPS': 'INIT_CAP', 'PTAG': 'PAD'},\n",
       " {'ID': 2, 'FORM': 'round', 'CAPS': 'NO_CAPS', 'PTAG': 'B-ORG'},\n",
       " {'ID': 3, 'FORM': 'table', 'CAPS': 'NO_CAPS', 'PTAG': 'I-ORG'},\n",
       " {'ID': 4, 'FORM': 'in', 'CAPS': 'NO_CAPS', 'PTAG': 'I-MISC'},\n",
       " {'ID': 5, 'FORM': 'Wall', 'CAPS': 'INIT_CAP', 'PTAG': 'I-MISC'},\n",
       " {'ID': 6, 'FORM': 'Street', 'CAPS': 'INIT_CAP', 'PTAG': 'E-ORG'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That _ _ _ PAD\n",
      "round _ _ _ B-ORG\n",
      "table _ _ _ I-ORG\n",
      "in _ _ _ I-MISC\n",
      "Wall _ _ _ I-MISC\n",
      "Street _ _ _ E-ORG\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scorer.format_corpus([sd]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[6168, 6168,  793, 6169, 6169]]),\n",
       "  tensor([[  6168,   6168,  43539, 102381,  51127],\n",
       "          [  6168,  43539, 102381,  51127,  23294],\n",
       "          [ 43539, 102381,  51127,  23294, 123348],\n",
       "          [102381,  51127,  23294, 123348,  20585],\n",
       "          [ 51127,  23294, 123348,  20585,  21362],\n",
       "          [ 23294, 123348,  20585,  21362,  70048],\n",
       "          [123348,  20585,  21362,  70048,    794],\n",
       "          [ 20585,  21362,  70048,    794,   6169],\n",
       "          [ 21362,  70048,    794,   6169,   6169]])],\n",
       " [tensor([[4, 4, 0, 5, 5]]),\n",
       "  tensor([[4, 4, 0, 3, 2],\n",
       "          [4, 0, 3, 2, 3],\n",
       "          [0, 3, 2, 3, 3],\n",
       "          [3, 2, 3, 3, 3],\n",
       "          [2, 3, 3, 3, 2],\n",
       "          [3, 3, 3, 2, 3],\n",
       "          [3, 3, 2, 3, 3],\n",
       "          [3, 2, 3, 3, 5],\n",
       "          [2, 3, 3, 5, 5]])])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2], X_caps_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [torch.cat((x, x_c), dim=-1)\n",
    "           for x, x_c in zip(X_train, X_caps_train)]\n",
    "X_val = [torch.cat((x, x_c), dim=-1)\n",
    "         for x, x_c in zip(X_val, X_caps_val)]\n",
    "X_test = [torch.cat((x, x_c), dim=-1)\n",
    "          for x, x_c in zip(X_test, X_caps_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([13]), tensor([16, 13, 15, 13, 13, 13, 15, 13, 13]), tensor([4, 8])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.7243, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[1].unsqueeze(dim=0), y_train[1].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6168, 6168,  793, 6169, 6169,    4,    4,    0,    5,    5]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 14, 10, 3, 11, 14, 13, 0, 14]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[1].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'FORM': '-DOCSTART-',\n",
       "   'PPOS': '-X-',\n",
       "   'PCHUNK': '-X-',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'E-ORG'}],\n",
       " [{'FORM': 'SOCCER',\n",
       "   'PPOS': 'NN',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'I-LOC'},\n",
       "  {'FORM': '-',\n",
       "   'PPOS': ':',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'PAD'},\n",
       "  {'FORM': 'JAPAN',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'S-LOC',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'I-LOC'},\n",
       "  {'FORM': 'GET',\n",
       "   'PPOS': 'VB',\n",
       "   'PCHUNK': 'B-VP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'I-ORG'},\n",
       "  {'FORM': 'LUCKY',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'PAD'},\n",
       "  {'FORM': 'WIN',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'I-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': ',',\n",
       "   'PPOS': ',',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'CHINA',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'S-PER',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'IN',\n",
       "   'PPOS': 'IN',\n",
       "   'PCHUNK': 'B-PP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'PAD'},\n",
       "  {'FORM': 'SURPRISE',\n",
       "   'PPOS': 'DT',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'E-LOC'},\n",
       "  {'FORM': 'DEFEAT',\n",
       "   'PPOS': 'NN',\n",
       "   'PCHUNK': 'I-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'PAD'},\n",
       "  {'FORM': '.',\n",
       "   'PPOS': '.',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'B-ORG'}]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict_sentences(test_dict[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, input_sentences, target_tags):\n",
    "        self.input_sentences = input_sentences\n",
    "        self.target_tags = target_tags\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_batch = self.input_sentences[idx]\n",
    "        tgt_batch = self.target_tags[idx]\n",
    "        return src_batch, tgt_batch\n",
    "\n",
    "    def collate(self, batch):\n",
    "        src_batch, tgt_batch = list(zip(*batch))\n",
    "        src_batch = pad_sequence(\n",
    "            src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "        tgt_batch = pad_sequence(\n",
    "            tgt_batch, padding_value=0, batch_first=True)  # We pad with 0 here\n",
    "        return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=train_dataset.collate)\n",
    "val_dataset = PairDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, collate_fn=val_dataset.collate)\n",
    "test_dataset = PairDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=test_dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        batch_cnt = 0\n",
    "        cnt = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            batch_cnt += 1\n",
    "            # mask = (y_batch != pos2idx['PAD'])\n",
    "            cnt += len(y_batch)\n",
    "            loss += model(X_batch, y_batch).item()\n",
    "        return loss/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []\n",
    "history['conll_score'] = []\n",
    "history['val_accuracy'] = []\n",
    "history['val_loss'] = []\n",
    "history['val_conll_score'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:18<00:00, 133.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8533\n",
      "Epoch: 0, best model saved\n",
      "Epoch: 0 Val. loss: 1.1887 Val. acc.: 0.9696 Val. CoNLL score: 0.8533\n",
      "Best figures at epoch 0:\n",
      " \tLoss: 1.1887 (ep. 0) \tAcc.: 0.9696 (ep. 0) \tCoNLL score: 0.8533 (ep. 0)\n",
      "Époque : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:26<00:00, 126.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8636\n",
      "Epoch: 1, best model saved\n",
      "Epoch: 1 Val. loss: 1.0810 Val. acc.: 0.9718 Val. CoNLL score: 0.8636\n",
      "Best figures at epoch 1:\n",
      " \tLoss: 1.0810 (ep. 1) \tAcc.: 0.9718 (ep. 1) \tCoNLL score: 0.8636 (ep. 1)\n",
      "Époque : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:24<00:00, 127.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8711\n",
      "Epoch: 2, best model saved\n",
      "Epoch: 2 Val. loss: 1.0504 Val. acc.: 0.9726 Val. CoNLL score: 0.8711\n",
      "Best figures at epoch 2:\n",
      " \tLoss: 1.0504 (ep. 2) \tAcc.: 0.9726 (ep. 2) \tCoNLL score: 0.8711 (ep. 2)\n",
      "Époque : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:23<00:00, 128.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8769\n",
      "Epoch: 3, best model saved\n",
      "Epoch: 3 Val. loss: 1.0204 Val. acc.: 0.9736 Val. CoNLL score: 0.8769\n",
      "Best figures at epoch 3:\n",
      " \tLoss: 1.0204 (ep. 3) \tAcc.: 0.9736 (ep. 3) \tCoNLL score: 0.8769 (ep. 3)\n",
      "Époque : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:20<00:00, 131.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8801\n",
      "Epoch: 4, best model saved\n",
      "Epoch: 4 Val. loss: 1.0078 Val. acc.: 0.9745 Val. CoNLL score: 0.8801\n",
      "Best figures at epoch 4:\n",
      " \tLoss: 1.0078 (ep. 4) \tAcc.: 0.9745 (ep. 4) \tCoNLL score: 0.8801 (ep. 4)\n",
      "Époque : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:19<00:00, 131.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8813\n",
      "Epoch: 5, best model saved\n",
      "Epoch: 5 Val. loss: 1.0109 Val. acc.: 0.9744 Val. CoNLL score: 0.8813\n",
      "Best figures at epoch 5:\n",
      " \tLoss: 1.0078 (ep. 4) \tAcc.: 0.9745 (ep. 4) \tCoNLL score: 0.8813 (ep. 5)\n",
      "Époque : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:20<00:00, 131.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8819\n",
      "Epoch: 6, best model saved\n",
      "Epoch: 6 Val. loss: 0.9943 Val. acc.: 0.9748 Val. CoNLL score: 0.8819\n",
      "Best figures at epoch 6:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9748 (ep. 6) \tCoNLL score: 0.8819 (ep. 6)\n",
      "Époque : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:25<00:00, 126.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8825\n",
      "Epoch: 7, best model saved\n",
      "Epoch: 7 Val. loss: 0.9985 Val. acc.: 0.9749 Val. CoNLL score: 0.8825\n",
      "Best figures at epoch 7:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9749 (ep. 7) \tCoNLL score: 0.8825 (ep. 7)\n",
      "Époque : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:27<00:00, 124.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8820\n",
      "Epoch: 8 Val. loss: 1.0030 Val. acc.: 0.9748 Val. CoNLL score: 0.8820\n",
      "Best figures at epoch 8:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9749 (ep. 7) \tCoNLL score: 0.8825 (ep. 7)\n",
      "Époque : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:30<00:00, 122.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8853\n",
      "Epoch: 9, best model saved\n",
      "Epoch: 9 Val. loss: 1.0022 Val. acc.: 0.9753 Val. CoNLL score: 0.8853\n",
      "Best figures at epoch 9:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9753 (ep. 9) \tCoNLL score: 0.8853 (ep. 9)\n",
      "Époque : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:36<00:00, 118.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8859\n",
      "Epoch: 10, best model saved\n",
      "Epoch: 10 Val. loss: 1.0077 Val. acc.: 0.9753 Val. CoNLL score: 0.8859\n",
      "Best figures at epoch 10:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9753 (ep. 10) \tCoNLL score: 0.8859 (ep. 10)\n",
      "Époque : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:35<00:00, 118.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8858\n",
      "Epoch: 11 Val. loss: 1.0032 Val. acc.: 0.9754 Val. CoNLL score: 0.8858\n",
      "Best figures at epoch 11:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9754 (ep. 11) \tCoNLL score: 0.8859 (ep. 10)\n",
      "Époque : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:37<00:00, 116.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8860\n",
      "Epoch: 12, best model saved\n",
      "Epoch: 12 Val. loss: 1.0170 Val. acc.: 0.9753 Val. CoNLL score: 0.8860\n",
      "Best figures at epoch 12:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9754 (ep. 11) \tCoNLL score: 0.8860 (ep. 12)\n",
      "Époque : 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:34<00:00, 119.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8876\n",
      "Epoch: 13, best model saved\n",
      "Epoch: 13 Val. loss: 1.0173 Val. acc.: 0.9758 Val. CoNLL score: 0.8876\n",
      "Best figures at epoch 13:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8876 (ep. 13)\n",
      "Époque : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:37<00:00, 117.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8858\n",
      "Epoch: 14 Val. loss: 1.0319 Val. acc.: 0.9748 Val. CoNLL score: 0.8858\n",
      "Best figures at epoch 14:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8876 (ep. 13)\n",
      "Époque : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:33<00:00, 119.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8879\n",
      "Epoch: 15, best model saved\n",
      "Epoch: 15 Val. loss: 1.0347 Val. acc.: 0.9757 Val. CoNLL score: 0.8879\n",
      "Best figures at epoch 15:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8879 (ep. 15)\n",
      "Époque : 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:28<00:00, 124.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8866\n",
      "Epoch: 16 Val. loss: 1.0344 Val. acc.: 0.9756 Val. CoNLL score: 0.8866\n",
      "Best figures at epoch 16:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8879 (ep. 15)\n",
      "Époque : 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:30<00:00, 122.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8873\n",
      "Epoch: 17 Val. loss: 1.0479 Val. acc.: 0.9756 Val. CoNLL score: 0.8873\n",
      "Best figures at epoch 17:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8879 (ep. 15)\n",
      "Époque : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:30<00:00, 122.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8878\n",
      "Epoch: 18 Val. loss: 1.0517 Val. acc.: 0.9756 Val. CoNLL score: 0.8878\n",
      "Best figures at epoch 18:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8879 (ep. 15)\n",
      "Époque : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:29<00:00, 123.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8883\n",
      "Epoch: 19, best model saved\n",
      "Epoch: 19 Val. loss: 1.0517 Val. acc.: 0.9758 Val. CoNLL score: 0.8883\n",
      "Best figures at epoch 19:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n",
      "Époque : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:30<00:00, 122.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8874\n",
      "Epoch: 20 Val. loss: 1.0558 Val. acc.: 0.9756 Val. CoNLL score: 0.8874\n",
      "Best figures at epoch 20:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n",
      "Époque : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:36<00:00, 117.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8862\n",
      "Epoch: 21 Val. loss: 1.0632 Val. acc.: 0.9753 Val. CoNLL score: 0.8862\n",
      "Best figures at epoch 21:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n",
      "Époque : 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [02:30<00:00, 122.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8863\n",
      "Epoch: 22 Val. loss: 1.0690 Val. acc.: 0.9754 Val. CoNLL score: 0.8863\n",
      "Best figures at epoch 22:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n",
      "Époque : 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [01:53<00:00, 162.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8861\n",
      "Epoch: 23 Val. loss: 1.0718 Val. acc.: 0.9755 Val. CoNLL score: 0.8861\n",
      "Best figures at epoch 23:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n",
      "Époque : 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18453/18453 [01:45<00:00, 175.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. CoNLL score: 0.8855\n",
      "Epoch: 24 Val. loss: 1.0791 Val. acc.: 0.9754 Val. CoNLL score: 0.8855\n",
      "Best figures at epoch 24:\n",
      " \tLoss: 0.9943 (ep. 6) \tAcc.: 0.9758 (ep. 13) \tCoNLL score: 0.8883 (ep. 19)\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1000\n",
    "best_acc = best_score = 0\n",
    "best_loss_epoch = best_acc_epoch = best_score_epoch = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Époque :', epoch)\n",
    "    train_loss = train_acc = 0.0\n",
    "    cnt = batch_cnt = 0\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(train_dataloader):\n",
    "        batch_cnt += 1\n",
    "        mask = (y_batch != pos2idx['PAD'])\n",
    "        cnt += mask.sum().item()\n",
    "        loss = model(X_batch, y_batch, mask=mask)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Loss\n",
    "        history['loss'] += [train_loss/cnt]\n",
    "        val_loss = evaluate(model, test_dataloader)\n",
    "        history['val_loss'] += [val_loss]\n",
    "        if val_loss < best_loss:\n",
    "            best_loss_epoch = epoch\n",
    "            best_loss = val_loss\n",
    "            if CORPUS == 'EWT':\n",
    "                torch.save(model, MODEL_FILE)\n",
    "                print(f'Epoch: {epoch}, model saved')\n",
    "        # CoNLL scores and accuracies\n",
    "        train_pred_sents = tagger.predict_sentences(train_dict)\n",
    "        train_accuracy = scorer.accuracy(train_pred_sents)\n",
    "        history['accuracy'] += [train_accuracy]\n",
    "        val_pred_sents = tagger.predict_sentences(val_dict)\n",
    "        val_accuracy = scorer.accuracy(val_pred_sents)\n",
    "        history['val_accuracy'] += [val_accuracy]\n",
    "        if val_accuracy > best_acc:\n",
    "            best_acc_epoch = epoch\n",
    "            best_acc = val_accuracy\n",
    "\n",
    "        if CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "            train_chunker_score = scorer.conll_score(train_pred_sents)\n",
    "            history['conll_score'] += [train_chunker_score]\n",
    "            val_chunker_score = scorer.conll_score(val_pred_sents)\n",
    "            history['val_conll_score'] += [val_chunker_score]\n",
    "            print(f'Val. CoNLL score: {val_chunker_score:.4f}')\n",
    "            if val_chunker_score > best_score:\n",
    "                best_score_epoch = epoch\n",
    "                best_score = val_chunker_score\n",
    "                torch.save(model, MODEL_FILE)\n",
    "                print(f'Epoch: {epoch}, best model saved')\n",
    "            print(\n",
    "                f'Epoch: {epoch}',\n",
    "                f'Val. loss: {val_loss:.4f}',\n",
    "                f'Val. acc.: {val_accuracy:.4f}',\n",
    "                f'Val. CoNLL score: {val_chunker_score:.4f}')\n",
    "        elif CORPUS == 'EWT':\n",
    "            print(\n",
    "                f'Epoch: {epoch}',\n",
    "                f'Val. loss: {val_loss:.4f}',\n",
    "                f'Val. acc.: {val_accuracy:.4f}')\n",
    "\n",
    "        # For the CoNLL corpus, we use the test set as validation set.\n",
    "        print(f'Best figures at epoch {epoch}:\\n',\n",
    "              f'\\tLoss: {best_loss:.4f} (ep. {best_loss_epoch})',\n",
    "              f'\\tAcc.: {best_acc:.4f} (ep. {best_acc_epoch})',\n",
    "              f'\\tCoNLL score: {best_score:.4f} (ep. {best_score_epoch})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "conll_score = history['conll_score']\n",
    "\n",
    "val_acc = history['val_accuracy']\n",
    "val_loss = history['val_loss']\n",
    "val_conll_score = history['val_conll_score']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation losses')\n",
    "plt.legend()\n",
    "\n",
    "if CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, conll_score, 'bo', label='Training score')\n",
    "    plt.plot(epochs, val_conll_score, 'b', label='Validation score')\n",
    "    plt.title('Training and validation scores')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicting a Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (word_embs): Embedding(136492, 50)\n",
       "  (cap_embs): Embedding(6, 5)\n",
       "  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "  (fc1): Linear(in_features=275, out_features=300, bias=True)\n",
       "  (hardth): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=300, out_features=18, bias=True)\n",
       "  (crf): CRF()\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(MODEL_FILE, weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the tagger model to the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 13, 14, 13, 13, 13, 13, 14, 13, 13, 13, 13]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred = model(X_test[1].unsqueeze(dim=0))\n",
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'S-LOC', 'O', 'O', 'O', 'O', 'S-LOC', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: idx2pos.get(x, 'UNK'), Y_test_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0517445309825817"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_test = evaluate(model, test_dataloader)\n",
    "loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = sorted(pos2idx.keys(), key=lambda x: pos2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'E-LOC',\n",
       " 'E-MISC',\n",
       " 'E-ORG',\n",
       " 'E-PER',\n",
       " 'I-LOC',\n",
       " 'I-MISC',\n",
       " 'I-ORG',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'S-LOC',\n",
       " 'S-MISC',\n",
       " 'S-ORG',\n",
       " 'S-PER']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"That round table might collapse .\",\n",
    "             \"The man can learn well .\",\n",
    "             \"The man can swim .\",\n",
    "             \"The man can simwo .\",\n",
    "             'The Soviet Union might collapse .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ID': 1, 'FORM': 'That', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 2, 'FORM': 'round', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 3, 'FORM': 'table', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 4, 'FORM': 'might', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 5, 'FORM': 'collapse', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 4, 'FORM': 'learn', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 5, 'FORM': 'well', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 4, 'FORM': 'swim', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 5, 'FORM': '.', 'CAPS': 'NO_CAPS'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 4, 'FORM': 'simwo', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 5, 'FORM': '.', 'CAPS': 'NO_CAPS'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 2, 'FORM': 'Soviet', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 3, 'FORM': 'Union', 'CAPS': 'INIT_CAP'},\n",
       "  {'ID': 4, 'FORM': 'might', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 5, 'FORM': 'collapse', 'CAPS': 'NO_CAPS'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS'}]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = [tagger.sent2dict(sent) for sent in sentences]\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ID': 1, 'FORM': 'That', 'CAPS': 'INIT_CAP', 'PTAG': 'O'},\n",
       "  {'ID': 2, 'FORM': 'round', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 3, 'FORM': 'table', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 4, 'FORM': 'might', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 5, 'FORM': 'collapse', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS', 'PTAG': 'O'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP', 'PTAG': 'O'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 4, 'FORM': 'learn', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 5, 'FORM': 'well', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS', 'PTAG': 'O'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP', 'PTAG': 'O'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 4, 'FORM': 'swim', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 5, 'FORM': '.', 'CAPS': 'NO_CAPS', 'PTAG': 'O'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP', 'PTAG': 'O'},\n",
       "  {'ID': 2, 'FORM': 'man', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 3, 'FORM': 'can', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 4, 'FORM': 'simwo', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 5, 'FORM': '.', 'CAPS': 'NO_CAPS', 'PTAG': 'O'}],\n",
       " [{'ID': 1, 'FORM': 'The', 'CAPS': 'INIT_CAP', 'PTAG': 'O'},\n",
       "  {'ID': 2, 'FORM': 'Soviet', 'CAPS': 'INIT_CAP', 'PTAG': 'B-LOC'},\n",
       "  {'ID': 3, 'FORM': 'Union', 'CAPS': 'INIT_CAP', 'PTAG': 'E-LOC'},\n",
       "  {'ID': 4, 'FORM': 'might', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 5, 'FORM': 'collapse', 'CAPS': 'NO_CAPS', 'PTAG': 'O'},\n",
       "  {'ID': 6, 'FORM': '.', 'CAPS': 'NO_CAPS', 'PTAG': 'O'}]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict_sentences(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Score\n",
    "The final score is the CoNLL validation score for CoNLL 2000 and 2003 and the accuracy score on the test set for EWT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_sents = tagger.predict_sentences(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'FORM': '-DOCSTART-',\n",
       "   'PPOS': '-X-',\n",
       "   'PCHUNK': '-X-',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'}],\n",
       " [{'FORM': 'SOCCER',\n",
       "   'PPOS': 'NN',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': '-',\n",
       "   'PPOS': ':',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'JAPAN',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'S-LOC',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'S-LOC'},\n",
       "  {'FORM': 'GET',\n",
       "   'PPOS': 'VB',\n",
       "   'PCHUNK': 'B-VP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'LUCKY',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'WIN',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'I-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': ',',\n",
       "   'PPOS': ',',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'CHINA',\n",
       "   'PPOS': 'NNP',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'S-PER',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'S-LOC'},\n",
       "  {'FORM': 'IN',\n",
       "   'PPOS': 'IN',\n",
       "   'PCHUNK': 'B-PP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'SURPRISE',\n",
       "   'PPOS': 'DT',\n",
       "   'PCHUNK': 'B-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': 'DEFEAT',\n",
       "   'PPOS': 'NN',\n",
       "   'PCHUNK': 'I-NP',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'ALL_CAPS',\n",
       "   'PTAG': 'O'},\n",
       "  {'FORM': '.',\n",
       "   'PPOS': '.',\n",
       "   'PCHUNK': 'O',\n",
       "   'NER': 'O',\n",
       "   'CAPS': 'NO_CAPS',\n",
       "   'PTAG': 'O'}]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoNLL score on the validation set: 0.8883\n"
     ]
    }
   ],
   "source": [
    "if CORPUS in ['CONLL2000', 'CONLL2003']:\n",
    "    chunker_score = scorer.conll_score(pred_test_sents)\n",
    "    print(f'CoNLL score on the validation set: {chunker_score:.4f}')\n",
    "elif CORPUS == 'EWT':\n",
    "    accuracy = scorer.accuracy(pred_test_sents)\n",
    "    print(f'Accuracy on the test set: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
